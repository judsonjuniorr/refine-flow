# RefineFlow

Agente de refinamento de atividades com IA e CLI interativa para gerenciamento de tarefas t√©cnicas.

> **Nota**: A interface do usu√°rio est√° completamente em portugu√™s brasileiro (pt-BR).

## ‚ú® Novidades na v0.2.0

üöÄ **Integra√ß√£o LangChain Completa**
- ‚úÖ Prompts otimizados com templates estruturados
- ‚úÖ Gerenciamento autom√°tico de tokens por modelo (20+ modelos OpenAI)
- ‚úÖ Suporte para reasoning models (O1 series) com detec√ß√£o autom√°tica
- ‚úÖ Output parsing com valida√ß√£o (JSON + String)
- ‚úÖ Logging detalhado de tokens e metadata

üìñ [Leia mais sobre a implementa√ß√£o LangChain](LANGCHAIN.md)

## Funcionalidades

- üéØ **Gerenciamento de Contexto**: Crie e mantenha contextos detalhados para cada atividade t√©cnica
- ü§ñ **An√°lise com IA**: Extra√ß√£o autom√°tica de itens de a√ß√£o, quest√µes, decis√µes e lacunas
- üìä **Business Case Canvas**: Gere documenta√ß√£o abrangente de business case
- üé´ **Exporta√ß√£o Jira**: Exporte atividades como tarefas pai com subtarefas backend/frontend
- üí¨ **Chat Interativo**: Perguntas e respostas com contexto e cita√ß√µes
- üìù **Armazenamento Markdown**: Todos os dados armazenados em arquivos Markdown leg√≠veis
- üîç **Busca Inteligente**: √çndice SQLite para pesquisa r√°pida de atividades

## Instala√ß√£o

### Requisitos

- Python 3.12 ou superior
- Chave de API OpenAI
- (Opcional) Ollama para embeddings

### Configura√ß√£o

#### Op√ß√£o 1: Setup Autom√°tico (Recomendado)

```bash
git clone <repository-url>
cd refinement-agent
./setup.sh
```

O script ir√°:
- Criar ambiente virtual
- Instalar todas as depend√™ncias
- Configurar .env
- Opcionalmente iniciar Ollama com Docker

#### Op√ß√£o 2: Setup Manual

1. Clone o reposit√≥rio:
```bash
git clone <repository-url>
cd refinement-agent
```

2. Crie um ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

3. Instale o pacote:
```bash
pip install -e ".[dev]"
```

**Ou use o Makefile:**
```bash
make install
```

4. Configure as vari√°veis de ambiente:
```bash
cp .env.example .env
# Edite .env e adicione sua chave de API OpenAI
```

> **Dica**: Use `make help` para ver todos os comandos dispon√≠veis.

## Configura√ß√£o

### Configura√ß√£o Obrigat√≥ria

Defina sua chave de API OpenAI no `.env`:
```env
OPENAI_API_KEY=sua-chave-api-aqui
OPENAI_MODEL=gpt-5-mini
```

### Opcional: Ollama para Embeddings

Se voc√™ quiser usar embeddings para busca sem√¢ntica, h√° duas op√ß√µes:

#### Op√ß√£o 1: Usando Docker Compose (Recomendado)

1. Inicie o Ollama com Docker Compose:
```bash
docker-compose up -d
```

O container ir√°:
- Subir o servidor Ollama na porta 11434
- Baixar automaticamente o modelo `snowflake-arctic-embed`
- Manter os dados persistentes no volume Docker

2. Configure no `.env`:
```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=snowflake-arctic-embed
ENABLE_EMBEDDINGS=true
```

3. Verificar status:
```bash
docker-compose logs -f ollama
```

4. Parar o servi√ßo:
```bash
docker-compose down
```

#### Op√ß√£o 2: Instala√ß√£o Local

1. Instale o [Ollama](https://ollama.ai/)
2. Baixe o modelo de embedding:
```bash
ollama pull snowflake-arctic-embed
```
3. Configure no `.env`:
```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=snowflake-arctic-embed
ENABLE_EMBEDDINGS=true
```

## Uso

### Iniciar a Aplica√ß√£o

```bash
refineflow
```

Ou usando o m√≥dulo Python:
```bash
python -m refineflow
```

### Fluxos Principais

#### 1. Criar uma Nova Atividade

1. Selecione "üìù Criar Nova Atividade" no menu principal
2. Responda as perguntas de inicializa√ß√£o:
   - T√≠tulo da Atividade
   - Breve Descri√ß√£o
   - Declara√ß√£o do Problema
   - Stakeholders (separados por v√≠rgula)
   - Restri√ß√µes/Cronograma
   - Sistema/Produto Afetado

O sistema cria uma estrutura de pastas com templates Markdown.

#### 2. Trabalhar em uma Atividade

1. Selecione "üîÑ Selecionar Atividade em Andamento"
2. Escolha dentre as atividades dispon√≠veis
3. Visualize o painel de status com resumo e a√ß√µes abertas
4. Op√ß√µes:
   - Adicionar informa√ß√£o (notas, perguntas, decis√µes, transcri√ß√µes, etc.)
   - Conversar com contexto
   - Gerar Business Case Canvas
   - Exportar para Jira
   - Finalizar atividade

#### 3. Adicionar Informa√ß√£o

Selecione o tipo de entrada:
- **Nota**: Observa√ß√£o ou informa√ß√£o geral
- **Pergunta**: Quest√£o aberta ou incerteza
- **Resposta**: Resposta a uma pergunta anterior
- **Transcri√ß√£o**: Transcri√ß√£o de reuni√£o ou conversa
- **Decis√£o**: Decis√£o documentada
- **Requisito**: Requisito funcional ou n√£o-funcional
- **Risco**: Risco identificado e mitiga√ß√£o
- **M√©trica**: M√©trica de sucesso ou KPI
- **Custo**: Estimativa de custo ou item de or√ßamento
- **Depend√™ncia**: Depend√™ncia interna ou externa

Escolha o m√©todo de entrada:
- **M√∫ltiplas linhas (terminal)**: Digite diretamente no terminal (ESC + Enter ou Ctrl+D para finalizar)
- **Editor do Sistema**: Abre o editor padr√£o do sistema ($EDITOR)

#### 4. Modo Conversa√ß√£o

Fa√ßa perguntas sobre o contexto da atividade. A IA ir√°:
- Usar todo o contexto dispon√≠vel de logs e estado
- Citar fontes (nomes de arquivos e timestamps)
- Fornecer insights relevantes

Digite 'sair' para retornar ao menu.

#### 5. Gerar Business Case Canvas

Cria um documento abrangente de business case cobrindo:
- Problema e Solu√ß√£o
- Recursos e Depend√™ncias
- Benef√≠cios e ROI
- Escopo e Cronograma
- Riscos e Mitiga√ß√µes
- Stakeholders
- An√°lise de Complexidade
- Plano de Comunica√ß√£o
- Custos e M√©tricas

O canvas destaca informa√ß√µes faltantes e sugere perguntas para complet√°-lo.

#### 6. Exportar para Jira

Gera:
- Tarefa pai com contexto completo
- Subtarefa de backend
- Subtarefa de frontend

Formatos de exporta√ß√£o:
- **Markdown**: Formatado para copiar e colar
- **JSON**: Dados estruturados
- **CSV**: Compat√≠vel com planilhas

#### 7. Finalizar Atividade

- Marca a atividade como completa
- Previne modifica√ß√µes futuras
- Permite consulta e exporta√ß√£o

## Estrutura do Projeto

```
data/
‚îî‚îÄ‚îÄ activities/
    ‚îî‚îÄ‚îÄ <slug-da-atividade>/
        ‚îú‚îÄ‚îÄ activity.md       # Vis√£o geral e metadados
        ‚îú‚îÄ‚îÄ log.md           # Entradas cronol√≥gicas
        ‚îú‚îÄ‚îÄ canvas.md        # Business Case Canvas
        ‚îú‚îÄ‚îÄ jira_export.md   # Sa√≠da da exporta√ß√£o Jira
        ‚îú‚îÄ‚îÄ state.json       # Estado estruturado
        ‚îî‚îÄ‚îÄ chat.md          # Hist√≥rico de conversas
```

## Desenvolvimento

### Comandos R√°pidos com Makefile

```bash
make help          # Lista todos os comandos dispon√≠veis
make install       # Instala o projeto
make test          # Executa testes
make test-cov      # Testes com cobertura
make lint          # Verifica c√≥digo
make format        # Formata c√≥digo
make run           # Inicia RefineFlow
make docker-up     # Inicia Ollama
make docker-logs   # Ver logs do Ollama
make docker-down   # Para Ollama
make setup         # Configura tudo (install + docker-up)
```

### Executar Testes

```bash
pytest
# ou
make test
```

### Verifica√ß√£o de Tipos

```bash
mypy src/refineflow
# ou
make type-check
```

### Linting

```bash
ruff check src/refineflow
ruff format src/refineflow
# ou
make format
```

## Arquitetura

- **Armazenamento**: Arquivos Markdown + √≠ndice SQLite
- **IA**: OpenAI API com **LangChain** para gera√ß√£o e an√°lise de texto
- **Prompts**: Templates estruturados com system/human messages em pt-BR
- **Token Management**: Otimiza√ß√£o autom√°tica baseada em modelo e tipo de tarefa
- **Output Parsing**: Valida√ß√£o autom√°tica com JsonOutputParser e StrOutputParser
- **Embeddings**: Integra√ß√£o opcional com Ollama para busca sem√¢ntica (via Docker)
- **Interface**: Rich panels e Questionary para menus interativos
- **Configura√ß√£o**: Pydantic settings com vari√°veis de ambiente

## Modelos Suportados

RefineFlow suporta automaticamente 20+ modelos OpenAI com otimiza√ß√£o de tokens:

- **GPT-4 Series**: gpt-4, gpt-4-32k, gpt-4-turbo, gpt-4-turbo-preview
- **GPT-4o Series**: gpt-4o, gpt-4o-mini (128K input / 16K output)
- **GPT-3.5 Series**: gpt-3.5-turbo, gpt-3.5-turbo-16k
- **O1 Series** (Reasoning): o1, o1-preview, o1-mini
  - ‚ö†Ô∏è Detec√ß√£o autom√°tica - remove par√¢metro `temperature`

Configure no `.env`:
```env
OPENAI_MODEL=gpt-4-turbo  # ou gpt-4o, o1-mini, etc
```

üìñ [Ver lista completa de modelos e limites](LANGCHAIN.md#modelos-suportados)

## Arquivos de Configura√ß√£o

- `docker-compose.yml` - Configura√ß√£o do Ollama com download autom√°tico do modelo
- `Makefile` - Comandos √∫teis para desenvolvimento
- `.env.example` - Template de vari√°veis de ambiente
- `pyproject.toml` - Configura√ß√£o do projeto Python
- `DOCKER.md` - Documenta√ß√£o detalhada do Docker

## Licen√ßa

MIT
