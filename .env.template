# Exemplo de configuração completa do RefineFlow
# Copie este arquivo para .env e ajuste conforme necessário

# OpenAI Configuration (OBRIGATÓRIO)
OPENAI_API_KEY=sk-proj-sua-chave-aqui
OPENAI_MODEL=gpt-5-mini

# Ollama Configuration (OPCIONAL - para embeddings)
# Se usar Docker Compose: make docker-up
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=snowflake-arctic-embed
ENABLE_EMBEDDINGS=true

# Application Configuration
DATA_DIR=./data
LOG_LEVEL=INFO

# ============================================
# GUIA DE CONFIGURAÇÃO
# ============================================
#
# 1. Configure sua chave OpenAI (obrigatório):
#    - Obtenha em: https://platform.openai.com/api-keys
#    - Substitua "sk-proj-sua-chave-aqui" pela sua chave real
#
# 2. Para usar embeddings com Ollama (opcional):
#    a) Com Docker (recomendado):
#       - Execute: make docker-up
#       - Aguarde o download do modelo (~2GB)
#       - Defina ENABLE_EMBEDDINGS=true
#    
#    b) Sem Docker:
#       - Instale Ollama: https://ollama.ai/
#       - Execute: ollama pull snowflake-arctic-embed
#       - Defina ENABLE_EMBEDDINGS=true
#
# 3. Personalize o diretório de dados (opcional):
#    - Altere DATA_DIR para o caminho desejado
#    - Exemplo: DATA_DIR=/home/user/refineflow-data
#
# 4. Ajuste o nível de log (opcional):
#    - DEBUG: Muito detalhado
#    - INFO: Informações normais (padrão)
#    - WARNING: Apenas avisos e erros
#    - ERROR: Apenas erros
